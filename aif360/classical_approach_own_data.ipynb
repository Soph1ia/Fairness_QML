{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classical ML + Fake Dataset\n",
    "- take decision tree to see if there is more or less 'fairness' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:No module named 'fairlearn': ExponentiatedGradientReduction will be unavailable. To install, run:\n",
      "pip install 'aif360[Reductions]'\n",
      "WARNING:root:No module named 'fairlearn': GridSearchReduction will be unavailable. To install, run:\n",
      "pip install 'aif360[Reductions]'\n",
      "WARNING:root:No module named 'inFairness': SenSeI and SenSR will be unavailable. To install, run:\n",
      "pip install 'aif360[inFairness]'\n",
      "WARNING:root:No module named 'fairlearn': GridSearchReduction will be unavailable. To install, run:\n",
      "pip install 'aif360[Reductions]'\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from aif360.metrics import ClassificationMetric\n",
    "from aif360.metrics import BinaryLabelDatasetMetric\n",
    "from aif360.datasets import StandardDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>income</th>\n",
       "      <th>gender</th>\n",
       "      <th>car</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>45</td>\n",
       "      <td>29923</td>\n",
       "      <td>male</td>\n",
       "      <td>yes</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>39</td>\n",
       "      <td>75755</td>\n",
       "      <td>male</td>\n",
       "      <td>yes</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>18</td>\n",
       "      <td>73277</td>\n",
       "      <td>male</td>\n",
       "      <td>yes</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>37</td>\n",
       "      <td>24442</td>\n",
       "      <td>male</td>\n",
       "      <td>yes</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>34</td>\n",
       "      <td>58901</td>\n",
       "      <td>male</td>\n",
       "      <td>yes</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age  income gender  car  target\n",
       "0   45   29923   male  yes       0\n",
       "1   39   75755   male  yes       0\n",
       "2   18   73277   male  yes       1\n",
       "3   37   24442   male  yes       0\n",
       "4   34   58901   male  yes       0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import the dataset\n",
    "fake_data_df = pd.read_csv(\"../aif360/Data/fake_data.csv\")\n",
    "fake_data_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocess The Data\n",
    "- remap the values "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remap gender to binary\n",
    "map = {'male': 0, 'female': 1}\n",
    "\n",
    "# replace values in gender column\n",
    "fake_data_df['gender'].replace(map, inplace=True)\n",
    "\n",
    "#remap the car column to binary\n",
    "map = {'yes': 0, 'no': 1}\n",
    "\n",
    "# replace values in car column\n",
    "fake_data_df['car'].replace(map, inplace=True)\n",
    "# spit the data into y and x \n",
    "y = fake_data_df['target']\n",
    "X = fake_data_df.drop(columns=['target'])\n",
    "\n",
    "# split the data into training and testing\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transform the data into Standard Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all training data into Standard Dataset\n",
    "train_all = pd.concat([X_train, y_train], axis=1)\n",
    "\n",
    "# all testing data into Standard Dataset\n",
    "test_all = pd.concat([X_test, y_test], axis=1)\n",
    "\n",
    "privileged_groups = [{'gender': 1}]\n",
    "unprivileged_groups = [{'gender': 0}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the StandardDataset\n",
    "train_dataset = StandardDataset(train_all, \n",
    "                          label_name='target', \n",
    "                          protected_attribute_names=['gender'],\n",
    "                          favorable_classes=[1],\n",
    "                          privileged_classes=[[1]]\n",
    "                          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the StandardDataset\n",
    "test_dataset = StandardDataset(test_all, \n",
    "                          label_name='target', \n",
    "                          protected_attribute_names=['gender'],\n",
    "                          favorable_classes=[1],\n",
    "                          privileged_classes=[[1]]\n",
    "                          )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the simple Decision Tree model\n",
    "- no hyperparam tuning "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.88\n"
     ]
    }
   ],
   "source": [
    "# train the decision tree on the x_train and y_train\n",
    "clf = DecisionTreeClassifier(random_state=42)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# predict the y_test\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "# calculate the accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "print(\"Accuracy: \", accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Investigate if the Decision Tree is 'fair'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create standard dataset for the predicted values \n",
    "predicted_test_dataset = test_dataset.copy()\n",
    "predicted_test_dataset.labels = y_pred.reshape(-1, 1)\n",
    "\n",
    "# Classification metrics \n",
    "metric_prediction = ClassificationMetric(test_dataset, \n",
    "                                        predicted_test_dataset, \n",
    "                                        unprivileged_groups=unprivileged_groups, \n",
    "                                        privileged_groups=privileged_groups)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The consistency is: [0.683]\n",
      "The disparate impact is: 0.13071895424836602\n",
      "The equal opportunity difference is: -0.625\n",
      "The average odds difference is: nan\n",
      "The statistical parity difference is: -0.869281045751634\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\badalova\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\aif360\\metrics\\classification_metric.py:278: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  TPR=TP / P, TNR=TN / N, FPR=FP / N, FNR=FN / P,\n",
      "C:\\Users\\badalova\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\aif360\\metrics\\classification_metric.py:279: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  GTPR=GTP / P, GTNR=GTN / N, GFPR=GFP / N, GFNR=GFN / P,\n"
     ]
    }
   ],
   "source": [
    "# compute the fairness of metric prediction\n",
    "print(\"The consistency is:\", metric_prediction.consistency()) \n",
    "\n",
    "# compute the fairness of metric prediction\n",
    "print(\"The disparate impact is:\", metric_prediction.disparate_impact())\n",
    "\n",
    "# compute the fairness of metric prediction\n",
    "print(\"The equal opportunity difference is:\", metric_prediction.equal_opportunity_difference())\n",
    "\n",
    "# compute the fairness of metric prediction\n",
    "print(\"The average odds difference is:\", metric_prediction.average_odds_difference()) # This is NAN?? \n",
    "\n",
    "# compute the fairness of metric prediction\n",
    "print(\"The statistical parity difference is:\", metric_prediction.statistical_parity_difference())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
